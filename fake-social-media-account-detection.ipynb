{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-16T10:51:24.880217Z","iopub.execute_input":"2023-02-16T10:51:24.880814Z","iopub.status.idle":"2023-02-16T10:51:24.900728Z","shell.execute_reply.started":"2023-02-16T10:51:24.880763Z","shell.execute_reply":"2023-02-16T10:51:24.899817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scenario\nA popular social media platform for sharing photos and videos has received complaints about fake user accounts. These fake accounts are said to have left spam comments on genuine user posts. Management has asked us to create a machine-learning model that will help the platform distinguish real versions from fake accounts. The company would then use the model to identify fake accounts so they can be deleted from the platform.\n![](https://www.endnowfoundation.org/wp-content/uploads/elementor/thumbs/Detect-Fake-Profiles-on-Social-Media-p6yfct3ismgslao8tyklprwyrfd5tttfiwrd6xcjuw.jpg)\n\n\nImage taken from: https://www.endnowfoundation.org/wp-content/uploads/elementor/thumbs/Detect-Fake-Profiles-on-Social-Media-p6yfct3ismgslao8tyklprwyrfd5tttfiwrd6xcjuw.jpg\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# 1) Goal\nThe goal here is to predict whether a user account is fake or not. A problem of this nature is called a binary classification problem (binary since we have two categories). We use int numbers to specify the two categories. In the 'fake' column, a 1 represents that the account in that row is fake, while a 0 indicates a real account.","metadata":{}},{"cell_type":"markdown","source":"# 2) Gather Data\nThe data is in the social_media_train.csv file. The target vector is given by the 'fake' column. Here the modules that typically are needed for reading and exploration are imported and then read in pandas DataFrame df_train.","metadata":{}},{"cell_type":"code","source":"# Import neccessary modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Note: Make sure module pdpipe is available. \n# You might need to install it via pip install pdpipe\nimport pdpipe as pdp\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:24.902850Z","iopub.execute_input":"2023-02-16T10:51:24.903538Z","iopub.status.idle":"2023-02-16T10:51:24.918244Z","shell.execute_reply.started":"2023-02-16T10:51:24.903501Z","shell.execute_reply":"2023-02-16T10:51:24.916634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Exploratory Data Analysis (EDA)\n## Understand Data\nIt is necessary to familiarize ourselves with the data at the beginning so that we know later what to look for while cleaning and preparing the data.","metadata":{}},{"cell_type":"code","source":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set max width of cell\npd.options.display.max_colwidth=300\n\n# Suppress scientific notation\nnp.set_printoptions(suppress=True) \npd.options.display.float_format = '{:.2f}'.format\n\n\n# Display all columns\npd.set_option('display.max_columns', None)\n\n# Read data\ndf_train = pd.read_csv(\"/kaggle/input/social-media-train/social_media_train.csv\",index_col=[0])\ndisplay(df_train.head(),df_train.info())\n","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:24.920093Z","iopub.execute_input":"2023-02-16T10:51:24.920802Z","iopub.status.idle":"2023-02-16T10:51:24.957908Z","shell.execute_reply.started":"2023-02-16T10:51:24.920750Z","shell.execute_reply":"2023-02-16T10:51:24.956802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each line of df_train represents a user or user account.\n","metadata":{}},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"# Dataset Description\ndata_dict = pd.read_csv('/kaggle/input/fake-account-data-dict/fake_account__data_dict.csv', index_col = 'No.')\ndata_dict","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:24.959681Z","iopub.execute_input":"2023-02-16T10:51:24.960562Z","iopub.status.idle":"2023-02-16T10:51:24.977798Z","shell.execute_reply.started":"2023-02-16T10:51:24.960513Z","shell.execute_reply":"2023-02-16T10:51:24.976974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determine categorical and numerical features\n\n# Numerical columns\nnum_cols = ['ratio_numlen_username','len_fullname','ratio_numlen_fullname',\n            'len_desc','num_posts','num_followers',\n              'num_following']\n# Categorical columns\ncat_cols = [col for col in df_train.columns.values.tolist() if col not in num_cols]\ncat_cols","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:24.979900Z","iopub.execute_input":"2023-02-16T10:51:24.980721Z","iopub.status.idle":"2023-02-16T10:51:24.989438Z","shell.execute_reply.started":"2023-02-16T10:51:24.980686Z","shell.execute_reply":"2023-02-16T10:51:24.988126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check descriptive statistics\ndf_train[num_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:24.991400Z","iopub.execute_input":"2023-02-16T10:51:24.991876Z","iopub.status.idle":"2023-02-16T10:51:25.035111Z","shell.execute_reply.started":"2023-02-16T10:51:24.991826Z","shell.execute_reply":"2023-02-16T10:51:25.033577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get an idea of target category share: fake\nplt.figure(figsize=(15,6))\nfake_share = df_train[\"fake\"].value_counts()\nmylabel=[\"Not fake(0)\",\"fake(1)\"]\ncolors = ['#99ff99','#ff9999']\nplt.pie(fake_share,\n        labels=mylabel,autopct=\"%1.1f%%\",colors=colors,\n        textprops={'fontsize': 16})\nplt.axis(\"equal\");","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:25.036725Z","iopub.execute_input":"2023-02-16T10:51:25.037071Z","iopub.status.idle":"2023-02-16T10:51:25.205804Z","shell.execute_reply.started":"2023-02-16T10:51:25.037040Z","shell.execute_reply":"2023-02-16T10:51:25.203754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target category is strongly balanced.\n","metadata":{}},{"cell_type":"code","source":"# Check the percentage of the missing values\n\npercent_missing = df_train.isnull().sum() * 100 / len(df_train)\nmissing_value_df = pd.DataFrame({'percent_missing (%)': percent_missing})\nmissing_value_df.sort_values('percent_missing (%)', ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:25.208490Z","iopub.execute_input":"2023-02-16T10:51:25.209177Z","iopub.status.idle":"2023-02-16T10:51:25.235930Z","shell.execute_reply.started":"2023-02-16T10:51:25.209137Z","shell.execute_reply":"2023-02-16T10:51:25.234562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation heatmap\n# Colormap: Most negative correlations (dark-blue) to most positive correlation (dark red)\ncorr = df_train[num_cols].corr()\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:25.237805Z","iopub.execute_input":"2023-02-16T10:51:25.238345Z","iopub.status.idle":"2023-02-16T10:51:25.274116Z","shell.execute_reply.started":"2023-02-16T10:51:25.238305Z","shell.execute_reply":"2023-02-16T10:51:25.272358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just like linear regression, logistic regression makes a number of assumptions. For continuous data, the following are relevant:\n* The features should not be strongly correlated with each other.\n* There should be a linear relationship between the features and the sigmoid transformed probabilities.\n\nAs can be seen all correlation values between features relatively close to 0.","metadata":{}},{"cell_type":"code","source":"# Pair plot oapif numerical values with fake account information\npp_cols = []\npp_cols = num_cols + ['fake']\nax=sns.pairplot(df_train[pp_cols], hue=\"fake\",corner=True);\nplt.style.use('fivethirtyeight')\nax.fig.suptitle(\"Pair Plot of Characteristics\")","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:25.280802Z","iopub.execute_input":"2023-02-16T10:51:25.281227Z","iopub.status.idle":"2023-02-16T10:51:34.323558Z","shell.execute_reply.started":"2023-02-16T10:51:25.281191Z","shell.execute_reply":"2023-02-16T10:51:34.322352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Very first finding:\n* As can be seen from pair plots above, fake accounts are more spread around the mean for ratio_numlen_username, ratio of numeric characters in the account username to their length. Values of real accounts, in this case, are strongly clustered around their mean. \n* Most fake accounnts have less words of descriptions (len_desc) in their bio, as the average of description words for fake accounts is less than real accounts.\n* ratio_numlen_fullname and ratio_numlen_username are correlated with eachother. Correlation matrix showes a value of +0.4085 for this correlation.\n* Average number of posts and followers of fake accounts are close to zero.\n ","metadata":{}},{"cell_type":"markdown","source":"Lets do some investigations of categorical data:","metadata":{}},{"cell_type":"code","source":"# Categorical data\ndisplay(df_train.loc[:, cat_cols].head())\nprint('----------------------')\n\n# Unique values\nfor col in cat_cols:\n    unique_values = df_train.loc[:, col].unique()\n    print(\"\\nColumn name: {}\\nUnique values: {}\".format(col, unique_values))  ","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:34.325157Z","iopub.execute_input":"2023-02-16T10:51:34.325675Z","iopub.status.idle":"2023-02-16T10:51:34.349337Z","shell.execute_reply.started":"2023-02-16T10:51:34.325631Z","shell.execute_reply":"2023-02-16T10:51:34.348037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define function label_encoding\ndef label_encoding(df):\n    '''\n    Function label_encoding() trnasforms categorical features\n    represented by strings to binary features containing only\n    0s and 1s which can be used for machine learning models.\n    Input:\n        DataFrame of features\n    Output:\n        New DataFrame with binary features    \n    '''\n    # label encoding\n    dict_label_encoding = {'Yes': 1, 'No': 0}\n    df.loc[:, 'profile_pic'] = df.loc[:, 'profile_pic'].replace(dict_label_encoding)\n    df.loc[:, 'extern_url'] = df.loc[:, 'extern_url'].replace(dict_label_encoding)\n    df.loc[:, 'private'] = df.loc[:, 'private'].replace(dict_label_encoding)\n\n    # one-hot encoding\n    onehot = pdp.OneHotEncode([\"sim_name_username\"], drop_first=False)\n    # fit and transform on train set\n    df = onehot.fit_transform(df)\n    return df       \n\n# Applay function label_encoding\ndf_train = label_encoding(df_train)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:34.350986Z","iopub.execute_input":"2023-02-16T10:51:34.351563Z","iopub.status.idle":"2023-02-16T10:51:34.385650Z","shell.execute_reply.started":"2023-02-16T10:51:34.351519Z","shell.execute_reply":"2023-02-16T10:51:34.384315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Logistic Regression\n\nIn this notebook, we first focus on Logistic Regression which is a known algorithm for classification tasks. Please see [this article](https://realpython.com/logistic-regression-python/#:~:text=The%20logistic%20regression%20function%20%F0%9D%91%9D(%F0%9D%90%B1)%20is%20the%20sigmoid%20function,that%20the%20output%20is%200.) for more details about logistic regresion.\n\nFrom regularization, we know that it can be helpful if a linear regression tries to minimize the slope values. For example, overfitting can be avoided.\nIn contrast to the logistic regression without regularization, the features must be standardized in the model with regularization. This is due to penalty parameters (l2 by default) in logistic regression: like linear regression, logistic regression with regularization makes the prediction dependent on the scaling of the features, where at 𝐿1 (Lasso) and 𝐿2 (Ridge) large coefficients are penalized more heavily. So, in order for the coefficients to be penalized equally, we need to standardize the coefficients.\n\n## Logistic Regression With And Without Regularization\nAs with linear regression and its Ridge and Lasso versions, logistic regression also allows for regularization. Please see [this article](https://www.andreaperlato.com/theorypost/ridge-and-lasso-regression/) for more details about regularisations.\n\nwe can now set up a logistic regression model By default, sklearn's logistic regression algorithm already uses regularization with the regularization parameter C=1.0. If we assign an extremely large value to C, such as a 1 followed by 42 zeros (1e42), no regularization is performed. That's what we want to achieve here first.\n\nThe algorithm needs many attempts to solve the problem. The default 100 iterations are not enough. Therefore, we should also assign a relatively large number to max_iter. This parameter sets the maximum number of iterations the solvers need to converge. 10000 (1e4) should suffice here.","metadata":{}},{"cell_type":"code","source":"# Import Logistic Regression model\nfrom sklearn.linear_model import LogisticRegression\n\n###################################################################\n# a) Without regularisation\n\n# Feature matrix and target vector\nfeatures_train = df_train.iloc[:, 1:]\ntarget_train = df_train.loc[:, 'fake']\n\n# Model instantiation\nmodel_log = LogisticRegression(solver='lbfgs', max_iter=1e4, C=1e42, random_state=42)\n\n# Model fitting\nmodel_log.fit(features_train, target_train)\n\n#####################################################################\n# b) With regularisation\n\n# Standardization to adjust the features\nfrom sklearn.preprocessing import StandardScaler \n\n# Fit on training data and scale them\nscaler = StandardScaler()\nfeatures_train_scaled = scaler.fit_transform(features_train)\n\n# Model instantiation\nmodel_reg = LogisticRegression(solver='lbfgs', max_iter=1e4, C=0.5, random_state=42)\n\n# Model fitting\nmodel_reg.fit(features_train_scaled, target_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:34.388524Z","iopub.execute_input":"2023-02-16T10:51:34.389310Z","iopub.status.idle":"2023-02-16T10:51:35.013250Z","shell.execute_reply.started":"2023-02-16T10:51:34.389243Z","shell.execute_reply":"2023-02-16T10:51:35.011815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Model Performance Evaluation \n\nWe use test data from social_media_test.csv for initial classification performance:","metadata":{}},{"cell_type":"code","source":"# Read data\ndf_test = pd.read_csv(\"/kaggle/input/social-media-test/social_media_test.csv\",index_col=[0])\ndf_test = label_encoding(df_test)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.017400Z","iopub.execute_input":"2023-02-16T10:51:35.017904Z","iopub.status.idle":"2023-02-16T10:51:35.049168Z","shell.execute_reply.started":"2023-02-16T10:51:35.017776Z","shell.execute_reply":"2023-02-16T10:51:35.048304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature matrix and target vector\nfeatures_test = df_test.drop('fake',axis=1)\ntarget_test = df_test['fake']\n\n # Without regularisation\n# predict target values from model\ntarget_test_pred_log = model_log.predict(features_test)\n\n# model evaluation\nfrom sklearn.metrics import precision_score, recall_score\nprecision_log = precision_score(target_test, target_test_pred_log)\nrecall_log = recall_score(target_test, target_test_pred_log)\n\n# print\nprint('Precision of model without regularisation: ', precision_log)\nprint('Recall of model without regularisation: ', recall_log)\n\n#####################################################################\n# With regularisation\n# features matrix and target vector\nfeatures_test_scaled = scaler.transform(features_test)\n\n# predict target values from model\ntarget_test_pred_reg = model_reg.predict(features_test_scaled)\n\n# model evaluation\nprecision_reg = precision_score(target_test, target_test_pred_reg)\nrecall_reg = recall_score(target_test, target_test_pred_reg)\n\n# print\nprint('Precision of model with regularisation: ', precision_reg)\nprint('Recall of model with regularisation: ', recall_reg)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.050712Z","iopub.execute_input":"2023-02-16T10:51:35.051095Z","iopub.status.idle":"2023-02-16T10:51:35.073821Z","shell.execute_reply.started":"2023-02-16T10:51:35.051061Z","shell.execute_reply":"2023-02-16T10:51:35.072578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model_log is better at recognizing actual fake accounts as such (recall), while model_reg has more actual fake accounts among predicted fake accounts (precision). In other words, model_log's predictions can be trusted a little less than model_reg.","metadata":{}},{"cell_type":"markdown","source":"## ROC (Receiver Operating Characteristic)\n\nLogisticRegression uses a threshold of 0.5 (50%) for determining the predicted categories. If we lower this threshold, there are more and more positive predictions and thus the recall increases. At the same time, however, the precision also decreases, because more and more of the predicted reference category cases are not fake at all.\n\n**The question here is which classification threshold suits our specific problem well?**    We can investigate this issue with the help of [ROC (Receiver Operating Characteristic) curve](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics). ROC curves are a nice way to see how any predictive classifier like logistic regression model can distinguish between the true positives and negatives.\n![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*7NVPwda0vt4obd_Q01t9Rw.png)\n\nThe ROC curve does this by plotting sensitivity, the probability of predicting a real positive will be a positive, against 1-specificity, the probability of predicting a real negative will be a positive. \n\n![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*b3ayb4TkvOdsNdDmJVQG1g.png)\n\nThe false positive rate is essentially a measure of how often a “false case” will occur — or, how often an actual negative instance will be classified as positive. \nFigure above demonstrates how some theoretical classifiers would plot on an ROC curve. The gray dotted line represents a classifier that is no better than random guessing — this will plot as a diagonal line. The purple line represents a perfect classifier — one with a true positive rate of 100% and a false positive rate of 0%. Nearly all real-world examples will fall somewhere between these two lines — not perfect, but providing more predictive power than random guessing. Typically, what we’re looking for is a classifier that maintains a high true positive rate while also having a low false positive rate — this ideal classifier would “hug” the upper left corner of Figure 1, much like the purple line in figure above. Image and text taken from: https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb\n\nBack to our problem, how can we compare two different implemented model above? What are the false positive rates for model_log and model_reg? how the recall  and the false positive rate change with the threshold. This can be investigated via ROC curve.\n\nThe roc_curve() function from sklearn.metrics calculates the values ​​of the curve. It needs the predicted probabilities. In a classification model, we always use my_model.predict() to predict the categories. Instead, if we want to know the probability of belonging to one category or another, we should use [my_model.predict_proba()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=%5Bsource%5D-,Probability%20estimates.,-The%20returned%20estimates).","metadata":{}},{"cell_type":"code","source":"# module import\nfrom sklearn.metrics import roc_curve\n\n# calculate roc curve values\ndef roc_curve_values(model,features,target):\n    '''\n    Function roc_curve_values estimates the probability\n    and return roc_curve values as output.\n    \n    Input:\n        model, feautes as dataframe, target values\n    Output:\n        False positive rate, recall, target_test_pred_proba\n    '''\n    # calculate probability\n    target_test_pred_proba = model.predict_proba(features) \n    \n    # calculate roc curve values\n    false_positive_rate, recall, threshold = roc_curve(target,\n                                                       target_test_pred_proba[:,1],\n                                                       drop_intermediate=False)\n    \n    return false_positive_rate, recall, target_test_pred_proba    ","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:50.513238Z","iopub.execute_input":"2023-02-16T10:51:50.513824Z","iopub.status.idle":"2023-02-16T10:51:50.520881Z","shell.execute_reply.started":"2023-02-16T10:51:50.513782Z","shell.execute_reply":"2023-02-16T10:51:50.519654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply function roc_curve_values for model without regularization\nfalse_positive_rate_log, recall_log, target_test_pred_proba_log  = roc_curve_values(model_log,features_test,target_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:50.931645Z","iopub.execute_input":"2023-02-16T10:51:50.932359Z","iopub.status.idle":"2023-02-16T10:51:50.940553Z","shell.execute_reply.started":"2023-02-16T10:51:50.932307Z","shell.execute_reply":"2023-02-16T10:51:50.939139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply function roc_curve_values for model with regularization\nfalse_positive_rate_reg, recall_reg, target_test_pred_proba_reg  = roc_curve_values(model_reg,features_test,target_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:51.135918Z","iopub.execute_input":"2023-02-16T10:51:51.136558Z","iopub.status.idle":"2023-02-16T10:51:51.143712Z","shell.execute_reply.started":"2023-02-16T10:51:51.136520Z","shell.execute_reply":"2023-02-16T10:51:51.142781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roc_curve_plot(false_positive_rate,recall,label):\n    '''\n    Function roc_curve_plot plots ROC\n    Input:\n        false_positive_rate, recall, label: model type\n    Output:\n        ROC plot    \n    '''\n    plt.style.use('fivethirtyeight')\n    fig,ax=plt.subplots()\n    \n    # Reference lines\n    # Blue diagonal\n    ax.plot([0, 1], ls = \"--\", label='random model')  \n    # Grey vertical\n    ax.plot([0, 0], [1, 0], c=\".7\", ls='--', label='ideal model') \n    # Grey horizontal\n    ax.plot([1, 1], c=\".7\", ls='--')  \n    \n    # ROC curve\n    ax.plot(false_positive_rate,recall, label = label)\n    \n    # labels\n    ax.set_title(\"Receiver Operating Characteristic\")\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"Recall\")\n    ax.legend()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.119783Z","iopub.execute_input":"2023-02-16T10:51:35.120151Z","iopub.status.idle":"2023-02-16T10:51:35.131698Z","shell.execute_reply.started":"2023-02-16T10:51:35.120119Z","shell.execute_reply":"2023-02-16T10:51:35.130598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_plot(false_positive_rate_log,recall_log,'model_log')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.132697Z","iopub.execute_input":"2023-02-16T10:51:35.133048Z","iopub.status.idle":"2023-02-16T10:51:35.401908Z","shell.execute_reply.started":"2023-02-16T10:51:35.133017Z","shell.execute_reply":"2023-02-16T10:51:35.400916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The red curve is the outcome from the model without regularization. From the recall of around 42% and from a false positive rate of approx. 19%, it hardly deviates from the ideal. So the model appears generally very good as it follows the gray ideal rather than the blue rate line. But it's not perfect.","metadata":{}},{"cell_type":"code","source":"roc_curve_plot(false_positive_rate_reg,recall_reg,'model_reg')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.403250Z","iopub.execute_input":"2023-02-16T10:51:35.403801Z","iopub.status.idle":"2023-02-16T10:51:35.666792Z","shell.execute_reply.started":"2023-02-16T10:51:35.403758Z","shell.execute_reply":"2023-02-16T10:51:35.665893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ROC curve of the model with regularization (model_reg) deviates a little more from the ideal gray dashed line of the model without regularization (model_log). This suggests that the logistic regression model with regularization is slightly worse in accuracy than the non-regularized model.","metadata":{}},{"cell_type":"markdown","source":"## ROC AUC Measure\n\nTo create a quantifiable model performance measure from the visual impression we just used, use the area under the curve. Hence the name of the model quality measure: receiver operator characteristic area under the curve (ROC-AUC).\n\nThe [ROC AUC score ](https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/#:~:text=The%20ROC%20AUC%20score%20tells,and%20the%20Negative%20class%20points.)tells us how efficient the model is. The higher the AUC, the better the model’s performance at distinguishing between the positive and negative classes. An AUC score of 1 means the classifier can perfectly distinguish between all the Positive and the Negative class points. An AUC value of 0 shows that the classifier predicts all Negatives as Positives and vice versa.\n![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*PU3_4LheadpGcpl6daO1mA.png)\n\nImage source: https://medium.com/the-owl/evaluation-metrics-part-3-47c315e07222","metadata":{}},{"cell_type":"code","source":"# Import roc_auc_score\nfrom sklearn.metrics import roc_auc_score\nprint('roc_auc_score for model without regularization', roc_auc_score(target_test, target_test_pred_proba_log[:, 1]))\nprint('##########################################################')\nprint('roc_auc_score for model with regularization', roc_auc_score(target_test, target_test_pred_proba_reg[:, 1]))","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.667982Z","iopub.execute_input":"2023-02-16T10:51:35.668513Z","iopub.status.idle":"2023-02-16T10:51:35.679954Z","shell.execute_reply.started":"2023-02-16T10:51:35.668477Z","shell.execute_reply":"2023-02-16T10:51:35.678370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing the score of the model without regularization 96%, to model with regularization 77%, it confirms our visual impression above: the model with regularization follows the ideal less than the model without regularization. The regularization has thus harmed the model quality rather than helped it. Regardless of the chosen decision thresholds, we can conclude that we have overfitted our model!","metadata":{}},{"cell_type":"markdown","source":"# 6) Find The Best Logistic Regression Model With Grid Search and ROC-AUC","metadata":{}},{"cell_type":"markdown","source":"We can now combine the accumulated knowledge. We will use the ROC AUC measure to find the best logistic regression model and then use it to predict the fake status of the social media accounts.\nThanks to the GridSearchCV the optimal hyperparameters of models can be found automatically. We can now turn to the pipeline containing the steps from data processing and feature engineering to prediction.\n\nBefore we can start the grid search, we still have to define the grid of hyperparameters that is to be searched:\n* Penalty: whether the regularization is like Ridge ('l2') or like LASSO ('l1')\n* C: Regularization weakness - Inverse of regularization strength\n\nSince we want to try both regularizations of ridge regression and lasso regression, we cannot use 'lbfgs' as before. Only the 'saga' setting supports both types of regularization. Please see [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver%7B%E2%80%98lbfgs%E2%80%99%2C%20%E2%80%98liblinear%E2%80%99%2C%20%E2%80%98newton%2Dcg%E2%80%99%2C%20%E2%80%98newton%2Dcholesky%E2%80%99%2C%20%E2%80%98sag%E2%80%99%2C%20%E2%80%98saga%E2%80%99%7D%2C%20default%3D%E2%80%99lbfgs%E2%80%99) for more details.\n\nIn order for the algorithm to find a good result, it has to make a relatively large number of attempts. Therefore, max_iter should be increased from the default of 100 iterations. 10000 iterations (1e4) seem to be enough.","metadata":{}},{"cell_type":"code","source":"# Import regured modules\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\n# Define pipeline\npipeline_log = Pipeline([('scaler',StandardScaler()),('classifier',LogisticRegression(solver='saga',\n                                                                  max_iter=1e4, \n                                                                  random_state=42))])\n# Determine search space of hyperparameters\nC_values = np.geomspace(start=0.001, stop=1000, num=14)\nsearch_space_grid = [{'classifier__penalty': ['l1', 'l2'],\n                      'classifier__C': C_values}]\n\n# Apply Grid Search\nmodel_grid = GridSearchCV(estimator=pipeline_log,\n                          param_grid=search_space_grid,\n                          scoring='roc_auc',\n                          cv=5,\n                          n_jobs=-1)\n\n# Model fitting\nmodel_grid.fit(features_train, target_train)\n\n# Print best estimater and score\nprint(model_grid.best_estimator_)\nprint(model_grid.best_params_)\nprint(model_grid.best_score_)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:35.681837Z","iopub.execute_input":"2023-02-16T10:51:35.682247Z","iopub.status.idle":"2023-02-16T10:51:45.970997Z","shell.execute_reply.started":"2023-02-16T10:51:35.682204Z","shell.execute_reply":"2023-02-16T10:51:45.969578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The logistic regression model that leads to this value uses a regularization like the ridge regression (penalty='l2') and regularizes a little less than the standard model (C=4.92).**","metadata":{}},{"cell_type":"markdown","source":"# 7) Model Evaluation With Test Data\n\nIt is best to check whether the extraordinarily good model quality according to cross-validation is also achieved with the test data.","metadata":{}},{"cell_type":"code","source":"# Apply function roc_curve_values for model with regularization\nfalse_positive_rate_grid, recall_grid, target_test_pred_proba  = roc_curve_values(model_grid,features_test,target_test)\nroc_curve_plot(false_positive_rate_grid,recall_grid,'model_grid')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:45.976224Z","iopub.execute_input":"2023-02-16T10:51:45.976643Z","iopub.status.idle":"2023-02-16T10:51:46.248600Z","shell.execute_reply.started":"2023-02-16T10:51:45.976604Z","shell.execute_reply":"2023-02-16T10:51:46.247354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculated roc_auc_score\ntarget_test_pred_proba = model_grid.predict_proba(features_test)\nroc_auc_score(target_test, target_test_pred_proba[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:46.250239Z","iopub.execute_input":"2023-02-16T10:51:46.250601Z","iopub.status.idle":"2023-02-16T10:51:46.264172Z","shell.execute_reply.started":"2023-02-16T10:51:46.250570Z","shell.execute_reply":"2023-02-16T10:51:46.262638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This value (ROC-AUC measure of 93.9%) is very good, but unfortunately slightly lower than the model figure of merit calculated using the validation data during the grid search. A discrepancy between model performance on test data and validation data is common.","metadata":{"execution":{"iopub.status.busy":"2023-02-15T14:41:00.617080Z","iopub.execute_input":"2023-02-15T14:41:00.617579Z","iopub.status.idle":"2023-02-15T14:41:00.626733Z","shell.execute_reply.started":"2023-02-15T14:41:00.617544Z","shell.execute_reply":"2023-02-15T14:41:00.624951Z"}}},{"cell_type":"markdown","source":"# 8) Prediction\n","metadata":{}},{"cell_type":"code","source":"# Read data\ndf_aim = pd.read_csv(\"/kaggle/input/social-media-aim/social_media_aim.csv\",index_col=[0])\ndf_aim = label_encoding(df_aim)\nfeatures_aim = df_aim.copy()\n\n# Apply Prediction \ndf_aim.loc[:, 'fake_pred_proba'] = model_grid.predict_proba(features_aim)[:, 1]\ndf_aim.loc[:, 'fake_pred'] = model_grid.predict(features_aim)\ndf_aim","metadata":{"execution":{"iopub.status.busy":"2023-02-16T10:51:46.265885Z","iopub.execute_input":"2023-02-16T10:51:46.266443Z","iopub.status.idle":"2023-02-16T10:51:46.309292Z","shell.execute_reply.started":"2023-02-16T10:51:46.266394Z","shell.execute_reply":"2023-02-16T10:51:46.307183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are two Instagram accounts where the model is absolutely sure about the categorization. The predicted fake probability is either exactly 1.0 or 0.0.\nFor the other five accounts, the model is less certain. Here the management can decide for itself which threshold value it wants to choose in order to block accounts. The classification with the default threshold of 0.5 can be seen in the 'fake_pred' column. She is a good first serve.\n\nUser accounts are now categorized into real and fake based on their characteristics. We've even exceeded management's expectations because they can now decide for themselves how secure the classification must be before an account is removed.","metadata":{}}]}